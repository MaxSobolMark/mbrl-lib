# @package _group_
policy_to_use: "CEM_PLANNING"
env: "gym___Swimmer-v2_pets_lifelong_learning"
num_distinct_envs: 6
envs:
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_forwards"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 0
    relabel_env_rewards: true
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_backwards"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 3.14159265359  # PI
    relabel_env_rewards: true
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_forwards_+45deg"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 0.785398  # PI / 4
    relabel_env_rewards: true
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_backwards_+45deg"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 3.92699  # 1.25 PI
    relabel_env_rewards: true
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_forwards_-45deg"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 5.49779  # 1.75 PI
    relabel_env_rewards: true
  -
    env_name: "gym___Swimmer-v2"
    wrappers: []
    task_name: "swimmer_backwards_-45deg"
    reward_fn: "Swimmer-v2"
    reward_fn_kwargs:
      goal: 2.35619449019  # 0.75 PI
    relabel_env_rewards: true
  

term_fn: "no_termination"
# obs_process_fn: none
learned_rewards: false
num_steps: 150000
trial_length: 1000
epoch_length: 1000

num_elites: 5
patience: 5
model_lr: 0.001
model_wd: 3e-5
model_batch_size: 256
validation_ratio: 0.
freq_train_model: 250
effective_model_rollouts_per_step: 400
rollout_schedule: [20, 100, 1, 1]
num_sac_updates_per_step: 20
sac_updates_every_steps: 1
num_epochs_to_retain_sac_buffer: 1

sac_critic_lr: 0.0003
sac_alpha_lr: 0.0003
sac_actor_lr: 0.0003
sac_actor_update_frequency: 4
sac_critic_target_update_frequency: 4
sac_target_entropy: -3
sac_hidden_depth: 2
sac_hidden_dim: 1024
sac_batch_size: 256

planning_horizon: 30
cem_num_iters: 5
cem_elite_ratio: 0.1
cem_population_size: 500  # 350
cem_alpha: 0.1

observe_task_id: false
forward_postprocess_fn: None

planning_mopo_penalty_coeff: 0
policy_mopo_penalty_coeff: 0
