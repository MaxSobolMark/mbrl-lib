# @package _group_
env: "pets_halfcheetah"
envs:
  -
    env_name: "pets_halfcheetah"
    wrappers: []
    task_name: "forward"
    reward_fn: "pets_halfcheetah"
  -
    env_name: "pets_halfcheetah"
    wrappers:
      -
        _target_: mbrl.env.wrappers.HalfCheetahBackwardsWrapper
    task_name: "backwards"
    reward_fn: "pets_halfcheetah_backwards"
  -
    env_name: "pets_halfcheetah"
    wrappers:
      -
        _target_: mbrl.env.wrappers.JumpWrapper
    task_name: "jump"
    reward_fn: "pets_halfcheetah_jump"
  -
    env_name: "pets_halfcheetah"
    wrappers: []
    task_name: "forward"
    reward_fn: "pets_halfcheetah"
  -
    env_name: "pets_halfcheetah"
    wrappers:
      - _target_: mbrl.env.wrappers.HalfCheetahBackwardsWrapper
    task_name: "backwards"
    reward_fn: "pets_halfcheetah_backwards"
  -
    env_name: "pets_halfcheetah"
    wrappers:
      - _target_: mbrl.env.wrappers.JumpWrapper
    task_name: "jump"
    reward_fn: "pets_halfcheetah_jump"
  
term_fn: "no_termination"
policy_to_use: CEM_PLANNING
obs_process_fn: mbrl.env.pets_halfcheetah.HalfCheetahEnv.preprocess_fn
learned_rewards: false
num_steps: 300000
trial_length: 1000

num_elites: 5
model_lr: 0.001  # 2e-4
model_wd: 3e-5
model_batch_size: 32
validation_ratio: 0
no_delta_list: [ 0 ]
freq_train_model: 1000
patience: 5  # 25
num_epochs_train_model: 5  # 25

planning_horizon: 30
cem_num_iters: 5
cem_elite_ratio: 0.1
cem_population_size: 500  # 350
cem_alpha: 0.1

# Dynamics model config
observe_task_id: true
forward_postprocess_fn: None
